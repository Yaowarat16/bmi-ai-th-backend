from fastapi import FastAPI, File, UploadFile, HTTPException
from PIL import Image
import io
import torch
import traceback
import os

from app.model import get_model
from app.utils import preprocess_image
from app.face_detector import has_face   # ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏Ñ‡∏ô‡∏Å‡πà‡∏≠‡∏ô

# =========================
# FastAPI App
# =========================
app = FastAPI(title="BMI AI API")

# ‚ö†Ô∏è ‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏•‡∏≤‡∏™‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•
CLASS_NAMES = ["underweight", "normal", "overweight"]

# confidence ‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤‡∏ô‡∏µ‡πâ = ‡∏õ‡∏è‡∏¥‡πÄ‡∏™‡∏ò (‡∏£‡∏π‡∏õ‡πÑ‡∏°‡πà‡∏ä‡∏±‡∏î / ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏Ñ‡∏ô)
MIN_CONFIDENCE = float(os.getenv("MIN_CONFIDENCE", "0.55"))


# =========================
# Health / Root
# =========================
@app.get("/")
def root():
    return {
        "status": "ok",
        "service": "BMI AI Backend"
    }


@app.get("/health")
def health():
    return {"health": "ok"}


# =========================
# Helper: extract tensor
# =========================
def _extract_tensor(output):
    """
    ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö TorchScript output ‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö:
    - Tensor
    - (Tensor,)
    - [Tensor]
    - dict ‡∏ó‡∏µ‡πà‡∏°‡∏µ Tensor
    """
    if isinstance(output, torch.Tensor):
        return output

    if isinstance(output, (list, tuple)) and len(output) > 0:
        if isinstance(output[0], torch.Tensor):
            return output[0]

    if isinstance(output, dict):
        for v in output.values():
            if isinstance(v, torch.Tensor):
                return v

    raise TypeError(f"Unsupported model output type: {type(output)}")


# =========================
# Predict Endpoint
# =========================
@app.post("/predict")
async def predict(file: UploadFile = File(...)):
    try:
        # -------------------------------------------------
        # 1) ‡∏ï‡∏£‡∏ß‡∏à content-type
        # -------------------------------------------------
        if file.content_type and not file.content_type.startswith("image/"):
            raise HTTPException(
                status_code=400,
                detail="Invalid file type. Please upload an image file."
            )

        # -------------------------------------------------
        # 2) ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå
        # -------------------------------------------------
        image_bytes = await file.read()
        if not image_bytes:
            raise HTTPException(
                status_code=400,
                detail="Empty file. Please upload an image."
            )

        # -------------------------------------------------
        # 3) ‡πÄ‡∏õ‡∏¥‡∏î‡∏£‡∏π‡∏õ
        # -------------------------------------------------
        try:
            image = Image.open(io.BytesIO(image_bytes)).convert("RGB")
        except Exception:
            raise HTTPException(
                status_code=400,
                detail="Cannot open image. Please upload a valid JPG/PNG file."
            )

        # -------------------------------------------------
        # üîí STEP 1: ‡∏ï‡∏£‡∏ß‡∏à‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏Ñ‡∏ô (‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î)
        # -------------------------------------------------
        if not has_face(image):
            raise HTTPException(
                status_code=422,
                detail="No human face detected. Please send a clear face photo."
            )

        # -------------------------------------------------
        # 4) ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• (cache)
        # -------------------------------------------------
        model = get_model()

        # -------------------------------------------------
        # 5) preprocess
        # -------------------------------------------------
        x = preprocess_image(image)

        # debug log (‡∏û‡∏≠‡πÄ‡∏´‡∏°‡∏≤‡∏∞)
        try:
            print("‚úÖ Input shape:", tuple(x.shape))
            print("‚úÖ Input dtype:", x.dtype)
            print("‚úÖ Input min/max:", float(x.min()), float(x.max()))
        except Exception:
            pass

        # -------------------------------------------------
        # 6) inference
        # -------------------------------------------------
        with torch.no_grad():
            output = model(x)
            logits = _extract_tensor(output)

        # -------------------------------------------------
        # 7) ‡∏à‡∏±‡∏î shape
        # -------------------------------------------------
        if logits.dim() == 1:
            logits = logits.unsqueeze(0)

        # -------------------------------------------------
        # 8) Classification
        # -------------------------------------------------
        if logits.dim() == 2 and logits.shape[1] > 1:
            probs = torch.softmax(logits, dim=1)
            pred = int(torch.argmax(probs, dim=1).item())
            conf = float(probs[0, pred].item())

            # ‚ùå confidence ‡∏ï‡πà‡∏≥ ‚Üí ‡∏õ‡∏è‡∏¥‡πÄ‡∏™‡∏ò
            if conf < MIN_CONFIDENCE:
                raise HTTPException(
                    status_code=422,
                    detail="Low confidence. Please send a clearer face photo."
                )

            class_name = (
                CLASS_NAMES[pred]
                if pred < len(CLASS_NAMES)
                else f"class_{pred}"
            )

            return {
                "class_id": pred,
                "class_name": class_name,
                "confidence": conf
            }

        # -------------------------------------------------
        # 9) Regression fallback (‡∏Å‡∏£‡∏ì‡∏µ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏î‡∏µ‡∏¢‡∏ß)
        # -------------------------------------------------
        value = float(logits.squeeze().item())
        return {"value": value}

    except HTTPException:
        raise

    except Exception as e:
        traceback.print_exc()
        raise HTTPException(
            status_code=500,
            detail=f"Prediction failed: {str(e)}"
        )
