import os
import torch

_MODEL = None
DEVICE = "cpu"

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ path ‡πÅ‡∏ö‡∏ö‡πÄ‡∏î‡∏¥‡∏°‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì (‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏ó‡∏±‡πâ‡∏á local)
DEFAULT_MODEL_PATH = r"D:\bmi-ai-api\weights\bmi_render.pt"

# ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ú‡πà‡∏≤‡∏ô ENV (‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å‡πÄ‡∏ß‡∏•‡∏≤‡∏Ç‡∏∂‡πâ‡∏ô Render)
# ‡πÄ‡∏ä‡πà‡∏ô ‡∏ï‡∏±‡πâ‡∏á MODEL_PATH=/opt/render/project/src/weights/bmi_render.pt
MODEL_PATH = os.getenv("MODEL_PATH", DEFAULT_MODEL_PATH)


def load_model():
    """
    ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• TorchScript (.pt) ‡∏î‡πâ‡∏ß‡∏¢ torch.jit.load
    - ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á architecture ‡πÉ‡∏´‡∏°‡πà
    - ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≥‡∏´‡∏ô‡∏î NUM_CLASSES
    """
    print("üöÄ Loading TorchScript model...")
    print(f"üì¶ MODEL_PATH: {MODEL_PATH}")
    print(f"üñ•Ô∏è DEVICE: {DEVICE}")

    if not os.path.exists(MODEL_PATH):
        raise FileNotFoundError(f"‚ùå Model file not found: {MODEL_PATH}")

    # ‚úÖ TorchScript ‡∏ï‡πâ‡∏≠‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏î‡πâ‡∏ß‡∏¢ jit.load
    model = torch.jit.load(MODEL_PATH, map_location=DEVICE)
    model.eval()

    print("‚úÖ Model loaded successfully (TorchScript)")
    return model


def get_model():
    """
    cache model (‡πÇ‡∏´‡∏•‡∏î‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ inference ‡πÄ‡∏£‡πá‡∏ß‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡πÇ‡∏´‡∏•‡∏î‡∏ã‡πâ‡∏≥‡∏ó‡∏∏‡∏Å request
    """
    global _MODEL
    if _MODEL is None:
        _MODEL = load_model()
    return _MODEL
